{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbb69d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = os.getenv(\"LANGSMITH_PROJECT\")\n",
    "os.environ[\"LANGCHAIN_TRACKING_V2\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6265b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "#model only\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\")\n",
    "result = llm.invoke(\"what is the capital of india\")\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae37e591",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The current Chief Minister of Kerala, India is Pinarayi Vijayan. He has been serving as the Chief Minister since May 25, 2016, and was re-elected for a second term on May 20, 2021. He is a member of the Communist Party of India (Marxist) and represents the Dharmadom constituency in the Kerala Legislative Assembly.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 120, 'prompt_tokens': 3276, 'total_tokens': 3396, 'completion_time': 0.303455, 'prompt_time': 0.093003, 'queue_time': 0.100619, 'total_time': 0.396457}, 'model_name': 'compound-beta-mini', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--7bc26ba4-f6f3-482e-88e4-df615f406184-0', usage_metadata={'input_tokens': 3276, 'output_tokens': 120, 'total_tokens': 3396})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"compound-beta-mini\")\n",
    "model.invoke(\"who is the chief minister of kerala,india\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5932a28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='Provide short answers to user queries'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prompt + model\n",
    "#PROMPT Engineering\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"Provide short answers to user queries\"),\n",
    "        (\"user\", \"{input}\")\n",
    "    ]\n",
    ")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aeb129c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current President of Iran is Masoud Pezeshkian. He has been in office since July 28, 2024, after winning the 2024 presidential election.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt|llm\n",
    "response = chain.invoke({\"input\":\"who is the president of iran \"})\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1c7140a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No, I am not human. I'm a computer program designed to simulate conversations and answer questions to the best of my ability. I'm an AI, specifically a large language model, built by Groq.\n"
     ]
    }
   ],
   "source": [
    "# prompt + model + outputParser\n",
    "\n",
    "#outputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt|model|output_parser\n",
    "\n",
    "response = chain.invoke({\"input\":\"are you a human or not\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2656464c",
   "metadata": {},
   "source": [
    "1️⃣ prompt: builds the input (prompt) for the model.\n",
    "2️⃣ model: generates an output (structured response).\n",
    "3️⃣ output_parser: parses the output to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "327da9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "output_parser = JsonOutputParser()\n",
    "output_parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fd9f024",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Jawaharlal Nehru', 'additional_info': {'term': 'First Prime Minister of India', 'tenure': 'August 15, 1947 - May 27, 1964'}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate #Prompt\n",
    "from langchain_groq import ChatGroq #Model\n",
    "from langchain_core.output_parsers import JsonOutputParser #OuptutParser\n",
    "\n",
    "#Step-1 : Prompt\n",
    "#prompt - not chatPromptTemplate, but PromptTemplate\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer user query \\n Return a JSON object. \\n {query} \\n \",\n",
    "    input_variables=[\"query\"]\n",
    ")\n",
    "\n",
    "#Step-2 : Model \n",
    "model = ChatGroq(model=\"compound-beta-mini\") \n",
    "\n",
    "#Step-3 : Output Parser\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "#Step-4 : Chaining\n",
    "chain = prompt|model|output_parser\n",
    "\n",
    "#Step-5 : Response\n",
    "response = chain.invoke({\"query\":\"who is the first prime minister of india\"})\n",
    "\n",
    "print(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "574b3f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Jawaharlal Nehru', 'designation': 'First Prime Minister of India', 'term': '1947-1964'}\n"
     ]
    }
   ],
   "source": [
    "#in standard, we manipulate prompt like\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate #Prompt\n",
    "from langchain_groq import ChatGroq #Model\n",
    "from langchain_core.output_parsers import JsonOutputParser #OuptutParser\n",
    "\n",
    "#Step-1 : Output Parser\n",
    "output_parser = JsonOutputParser()\n",
    "\n",
    "#Step-2 : Model \n",
    "model = ChatGroq(model=\"compound-beta-mini\") \n",
    "\n",
    "#Step-3 : Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer user query \\n {format_instruction} \\n {query} \\n \",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instruction\":output_parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "#Step-4 : Chaining\n",
    "chain = prompt|model|output_parser\n",
    "\n",
    "#Step-5 : Response\n",
    "response = chain.invoke({\"query\":\"who is the first prime minister of india\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5b726a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': 'who is the goat of football', 'response': {'GOAT of Football': 'Lionel Messi', 'Reason': \"Lionel Messi is widely regarded as the Greatest of All Time (GOAT) in football, with numerous accolades and records, including winning the World Cup in 2022 and multiple Ballon d'Or awards.\", 'Other Contenders': ['Cristiano Ronaldo', 'Pelé', 'Diego Maradona', 'Johan Cruyff', 'Zinedine Zidane', 'Michel Platini', 'Alfredo Di Stefano'], 'Context': 'The debate about the GOAT of football is ongoing, with various opinions and perspectives. However, based on recent trends and expert opinions, Lionel Messi is often considered the GOAT.'}}\n"
     ]
    }
   ],
   "source": [
    "# chatPromptTemplate : it is like an conversational prompt .systems says, user says, then sytem, then user.....\n",
    "# PromptTemplate : single converstation\n",
    "\n",
    "#using chatPromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"answer user queries in json format \"),\n",
    "        (\"user\",\"{query}\")\n",
    "    ]\n",
    ")\n",
    "response = chain.invoke({\"query\":\"who is the goat of football\"})\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
